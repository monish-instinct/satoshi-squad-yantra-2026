{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a758948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TRAIN set loaded successfully!\n",
      "   - Classes found: ['Fake', 'Real']\n",
      "   - Total images: 661\n",
      "   - Class mapping: {'Fake': 0, 'Real': 1}\n",
      "\n",
      "✅ TEST set loaded successfully!\n",
      "   - Classes found: ['Fake', 'Real']\n",
      "   - Total images: 449\n",
      "   - Class mapping: {'Fake': 0, 'Real': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets\n",
    "\n",
    "# 1. SET YOUR PATH\n",
    "data_dir = 'E:/ML_Pharamachain\\data\\dataset' \n",
    "\n",
    "def verify_data(path):\n",
    "    for split in ['train', 'test']:\n",
    "        split_path = os.path.join(path, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            print(f\"❌ Error: Could not find {split} folder at {split_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Try loading with ImageFolder to see what PyTorch sees\n",
    "        try:\n",
    "            temp_data = datasets.ImageFolder(root=split_path)\n",
    "            print(f\"✅ {split.upper()} set loaded successfully!\")\n",
    "            print(f\"   - Classes found: {temp_data.classes}\")\n",
    "            print(f\"   - Total images: {len(temp_data)}\")\n",
    "            print(f\"   - Class mapping: {temp_data.class_to_idx}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {split}: {e}\")\n",
    "\n",
    "verify_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77654ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch 1/5 | Loss: 0.1879\n",
      "Epoch 2/5 | Loss: 0.0131\n",
      "Epoch 3/5 | Loss: 0.0058\n",
      "Epoch 4/5 | Loss: 0.0027\n",
      "Epoch 5/5 | Loss: 0.0029\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 2. HYPERPARAMETERS\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=5 \n",
    "\n",
    "# 3. PREPROCESSING\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 4. LOAD DATASET\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 5. DEFINE MODEL\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, 2) # 2 classes: Fake/Real\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 6. TRAINING LOOP\n",
    "print(\"Starting Training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f55832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Model on Test Set...\n",
      "\n",
      "✅ Test Accuracy: 100.00%\n",
      "Correctly Classified: 449/449\n",
      "\n",
      "==================================================\n",
      "Classification Report:\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       1.00      1.00      1.00       162\n",
      "        Real       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       449\n",
      "   macro avg       1.00      1.00      1.00       449\n",
      "weighted avg       1.00      1.00      1.00       449\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[162   0]\n",
      " [  0 287]]\n",
      "\n",
      "==================================================\n",
      "Checking for Data Leakage...\n",
      "==================================================\n",
      "Train images: 646\n",
      "Test images: 444\n",
      "Duplicate images: 444\n",
      "\n",
      "⚠️  WARNING: Found 444 duplicate images between train and test!\n",
      "This causes data leakage and inflates accuracy scores.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. EVALUATION\n",
    "print(\"\\nEvaluating Model on Test Set...\")\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Correctly Classified: {correct}/{total}\")\n",
    "\n",
    "# Print per-class accuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "class_names = test_data.classes\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(cm)\n",
    "\n",
    "# 8. CHECK FOR DATA LEAKAGE (Duplicates between train and test)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Checking for Data Leakage...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "def get_file_hash(filepath):\n",
    "    \"\"\"Compute hash of a file to detect duplicates\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def check_duplicate_images(train_path, test_path):\n",
    "    \"\"\"Check if same images exist in both train and test\"\"\"\n",
    "    train_hashes = {}\n",
    "    test_hashes = {}\n",
    "    \n",
    "    # Get hashes for train images\n",
    "    for root, dirs, files in os.walk(train_path):\n",
    "        for file in files:\n",
    "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                filepath = os.path.join(root, file)\n",
    "                try:\n",
    "                    file_hash = get_file_hash(filepath)\n",
    "                    train_hashes[file_hash] = filepath\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Get hashes for test images\n",
    "    for root, dirs, files in os.walk(test_path):\n",
    "        for file in files:\n",
    "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                filepath = os.path.join(root, file)\n",
    "                try:\n",
    "                    file_hash = get_file_hash(filepath)\n",
    "                    test_hashes[file_hash] = filepath\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Find duplicates\n",
    "    duplicates = set(train_hashes.keys()) & set(test_hashes.keys())\n",
    "    \n",
    "    print(f\"Train images: {len(train_hashes)}\")\n",
    "    print(f\"Test images: {len(test_hashes)}\")\n",
    "    print(f\"Duplicate images: {len(duplicates)}\")\n",
    "    \n",
    "    if duplicates:\n",
    "        print(f\"\\n⚠️  WARNING: Found {len(duplicates)} duplicate images between train and test!\")\n",
    "        print(\"This causes data leakage and inflates accuracy scores.\\n\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\n✅ No duplicates found - dataset is properly split!\")\n",
    "        return False\n",
    "\n",
    "train_test_path = os.path.join(data_dir, 'train')\n",
    "test_test_path = os.path.join(data_dir, 'test')\n",
    "has_leakage = check_duplicate_images(train_test_path, test_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64e6f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OPTIMAL DATASET STRATEGY FOR BEST LEARNING\n",
      "============================================================\n",
      "\n",
      " DATA AUGMENTATION FOR TRAINING\n",
      "------------------------------------------------------------\n",
      "\n",
      "Data augmentation increases effective dataset size and prevents overfitting:\n",
      "\n",
      "Recommended augmentations:\n",
      "- Random horizontal flip (50% chance)\n",
      "- Random rotation (±15 degrees)\n",
      "- Random brightness/contrast adjustment\n",
      "- Random crops and resizing\n",
      "- ColorJitter for lighting variations\n",
      "\n",
      "✅ Augmentation transforms defined!\n",
      "\n",
      "3️⃣  BEST PRACTICES FOR OPTIMAL LEARNING\n",
      "------------------------------------------------------------\n",
      "\n",
      "✓ DATASET SPLIT: 70% train, 15% val, 15% test (prevents data leakage)\n",
      "✓ NO DUPLICATES: Check between train/test before training\n",
      "✓ CLASS BALANCE: Equal images per class (or use class_weight in loss)\n",
      "✓ DATA AUGMENTATION: Only on training data, not validation/test\n",
      "✓ BATCH SIZE: Use 32-64 for typical GPUs (memory dependent)\n",
      "✓ EPOCHS: Start with 10-20, use validation loss to determine optimal\n",
      "✓ LEARNING RATE: 0.0001 is good, monitor and adjust\n",
      "✓ VALIDATION: Monitor val loss to detect overfitting\n",
      "✓ EARLY STOPPING: Stop training if val loss doesn't improve\n",
      "\n",
      "Metrics to track:\n",
      "- Training loss (should decrease)\n",
      "- Validation loss (should decrease, if increases = overfitting)\n",
      "- Validation accuracy (should increase)\n",
      "\n",
      "\n",
      "4️⃣  CHECKING CLASS BALANCE\n",
      "------------------------------------------------------------\n",
      "TRAIN: Fake=240 (36.3%) | Real=422 (63.7%)\n",
      "VAL: Fake=167 (36.8%) | Real=287 (63.2%)\n",
      "TEST: Fake=162 (36.0%) | Real=288 (64.0%)\n"
     ]
    }
   ],
   "source": [
    "# 9. OPTIMAL DATASET SETUP\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMAL DATASET STRATEGY FOR BEST LEARNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "def create_optimal_dataset(raw_data_dir, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Creates optimal train/val/test split from raw data\n",
    "    \n",
    "    Parameters:\n",
    "    - raw_data_dir: Path containing Fake/ and Real/ folders with all images\n",
    "    - output_dir: Where to save organized train/val/test folders\n",
    "    - Ratios: 70% train, 15% val, 15% test (prevents overfitting)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n1️⃣  SPLITTING DATASET PROPERLY\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for class_name in ['Fake', 'Real']:\n",
    "        class_dir = os.path.join(raw_data_dir, class_name)\n",
    "        \n",
    "        if not os.path.exists(class_dir):\n",
    "            print(f\"⚠️  Class folder not found: {class_dir}\")\n",
    "            continue\n",
    "        \n",
    "        # Get all images\n",
    "        images = [f for f in os.listdir(class_dir) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "        \n",
    "        print(f\"\\n{class_name}: Found {len(images)} images\")\n",
    "        \n",
    "        # First split: train vs (val+test)\n",
    "        train_imgs, temp_imgs = train_test_split(\n",
    "            images, \n",
    "            test_size=(val_ratio + test_ratio),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Second split: val vs test\n",
    "        val_imgs, test_imgs = train_test_split(\n",
    "            temp_imgs,\n",
    "            test_size=(test_ratio / (val_ratio + test_ratio)),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Create directories\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_class_dir = os.path.join(output_dir, split, class_name)\n",
    "            os.makedirs(split_class_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy files\n",
    "        for img in train_imgs:\n",
    "            src = os.path.join(class_dir, img)\n",
    "            dst = os.path.join(output_dir, 'train', class_name, img)\n",
    "            if os.path.exists(src):\n",
    "                shutil.copy2(src, dst)\n",
    "        \n",
    "        for img in val_imgs:\n",
    "            src = os.path.join(class_dir, img)\n",
    "            dst = os.path.join(output_dir, 'val', class_name, img)\n",
    "            if os.path.exists(src):\n",
    "                shutil.copy2(src, dst)\n",
    "        \n",
    "        for img in test_imgs:\n",
    "            src = os.path.join(class_dir, img)\n",
    "            dst = os.path.join(output_dir, 'test', class_name, img)\n",
    "            if os.path.exists(src):\n",
    "                shutil.copy2(src, dst)\n",
    "        \n",
    "        print(f\"  ✅ Train: {len(train_imgs)} | Val: {len(val_imgs)} | Test: {len(test_imgs)}\")\n",
    "    \n",
    "    print(\"\\n✅ Dataset split complete!\")\n",
    "\n",
    "print(\"\\n DATA AUGMENTATION FOR TRAINING\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "Data augmentation increases effective dataset size and prevents overfitting:\n",
    "\n",
    "Recommended augmentations:\n",
    "- Random horizontal flip (50% chance)\n",
    "- Random rotation (±15 degrees)\n",
    "- Random brightness/contrast adjustment\n",
    "- Random crops and resizing\n",
    "- ColorJitter for lighting variations\n",
    "\"\"\")\n",
    "\n",
    "# Enhanced transform with augmentation for TRAINING\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# NO augmentation for validation/test (use original images)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"✅ Augmentation transforms defined!\")\n",
    "\n",
    "print(\"\\n3️⃣  BEST PRACTICES FOR OPTIMAL LEARNING\")\n",
    "print(\"-\" * 60)\n",
    "best_practices = \"\"\"\n",
    "✓ DATASET SPLIT: 70% train, 15% val, 15% test (prevents data leakage)\n",
    "✓ NO DUPLICATES: Check between train/test before training\n",
    "✓ CLASS BALANCE: Equal images per class (or use class_weight in loss)\n",
    "✓ DATA AUGMENTATION: Only on training data, not validation/test\n",
    "✓ BATCH SIZE: Use 32-64 for typical GPUs (memory dependent)\n",
    "✓ EPOCHS: Start with 10-20, use validation loss to determine optimal\n",
    "✓ LEARNING RATE: 0.0001 is good, monitor and adjust\n",
    "✓ VALIDATION: Monitor val loss to detect overfitting\n",
    "✓ EARLY STOPPING: Stop training if val loss doesn't improve\n",
    "\n",
    "Metrics to track:\n",
    "- Training loss (should decrease)\n",
    "- Validation loss (should decrease, if increases = overfitting)\n",
    "- Validation accuracy (should increase)\n",
    "\"\"\"\n",
    "print(best_practices)\n",
    "\n",
    "print(\"\\n4️⃣  CHECKING CLASS BALANCE\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# If you have train/val/test folders, check balance\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_path = os.path.join(data_dir, split)\n",
    "    if os.path.exists(split_path):\n",
    "        fake_count = len(os.listdir(os.path.join(split_path, 'Fake'))) if os.path.exists(os.path.join(split_path, 'Fake')) else 0\n",
    "        real_count = len(os.listdir(os.path.join(split_path, 'Real'))) if os.path.exists(os.path.join(split_path, 'Real')) else 0\n",
    "        total = fake_count + real_count\n",
    "        \n",
    "        if total > 0:\n",
    "            fake_pct = (fake_count / total) * 100\n",
    "            real_pct = (real_count / total) * 100\n",
    "            print(f\"{split.upper()}: Fake={fake_count} ({fake_pct:.1f}%) | Real={real_count} ({real_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bd41013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPREHENSIVE MODEL TESTING\n",
      "============================================================\n",
      "\n",
      "1️⃣  DETAILED METRICS\n",
      "------------------------------------------------------------\n",
      "Accuracy:  100.00%\n",
      "Precision: 1.0000\n",
      "Recall:    1.0000\n",
      "F1-Score:  1.0000\n",
      "\n",
      "2️⃣  PER-CLASS METRICS\n",
      "------------------------------------------------------------\n",
      "\n",
      "FAKE:\n",
      "  Accuracy:  100.00%\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-Score:  1.0000\n",
      "\n",
      "REAL:\n",
      "  Accuracy:  100.00%\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-Score:  1.0000\n",
      "\n",
      "3️⃣  CONFUSION MATRIX VISUALIZATION\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion matrix displayed!\n",
      "\n",
      "4️⃣  TESTING ON INDIVIDUAL IMAGES\n",
      "------------------------------------------------------------\n",
      "\n",
      "Example: Test a single image\n",
      "--------\n",
      "image_path = 'E:/ML_Pharamachain/data/dataset/test/Fake/image123.jpg'\n",
      "predicted_class, confidence, probabilities = test_single_image(\n",
      "    image_path, model, val_test_transform, device, class_names\n",
      ")\n",
      "\n",
      "print(f\"Predicted: {predicted_class} ({confidence:.2f}% confidence)\")\n",
      "print(f\"Probabilities: Fake={probabilities[0]*100:.2f}%, Real={probabilities[1]*100:.2f}%\")\n",
      "\n",
      "\n",
      "5️⃣  TESTING SUMMARY\n",
      "------------------------------------------------------------\n",
      "\n",
      "Total test images: 449\n",
      "Correct predictions: 449\n",
      "Incorrect predictions: 0\n",
      "\n",
      "Model is ✅ GOOD\n",
      "- If accuracy < 60%: Try more training, better data, or different model\n",
      "- If accuracy 60-80%: Good, but can be improved with more data/epochs\n",
      "- If accuracy > 80%: Excellent performance!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. COMPREHENSIVE TESTING & VISUALIZATION\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPREHENSIVE MODEL TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_score, recall_score\n",
    "\n",
    "# Test function for individual images\n",
    "def test_single_image(image_path, model, transform, device, class_names):\n",
    "    \"\"\"Test model on a single image\"\"\"\n",
    "    from PIL import Image\n",
    "    \n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    confidence_score = confidence.item() * 100\n",
    "    \n",
    "    return predicted_class, confidence_score, probabilities.cpu().numpy()[0]\n",
    "\n",
    "# Test function for batch\n",
    "def test_batch(loader, model, device, class_names):\n",
    "    \"\"\"Test model on entire batch\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "print(\"\\n1️⃣  DETAILED METRICS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Get predictions\n",
    "test_preds, test_labels, test_probs = test_batch(test_loader, model, device, class_names)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = np.mean(test_preds == test_labels) * 100\n",
    "precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\n",
    "recall = recall_score(test_labels, test_preds, average='weighted', zero_division=0)\n",
    "f1 = f1_score(test_labels, test_preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\n2️⃣  PER-CLASS METRICS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_mask = test_labels == i\n",
    "    class_acc = np.mean(test_preds[class_mask] == test_labels[class_mask]) * 100 if np.sum(class_mask) > 0 else 0\n",
    "    class_prec = precision_score(test_labels, test_preds, labels=[i], average=None, zero_division=0)[0]\n",
    "    class_rec = recall_score(test_labels, test_preds, labels=[i], average=None, zero_division=0)[0]\n",
    "    class_f1 = f1_score(test_labels, test_preds, labels=[i], average=None, zero_division=0)[0]\n",
    "    \n",
    "    print(f\"\\n{class_name.upper()}:\")\n",
    "    print(f\"  Accuracy:  {class_acc:.2f}%\")\n",
    "    print(f\"  Precision: {class_prec:.4f}\")\n",
    "    print(f\"  Recall:    {class_rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {class_f1:.4f}\")\n",
    "\n",
    "print(\"\\n3️⃣  CONFUSION MATRIX VISUALIZATION\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Confusion matrix displayed!\")\n",
    "\n",
    "print(\"\\n4️⃣  TESTING ON INDIVIDUAL IMAGES\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "Example: Test a single image\n",
    "--------\n",
    "image_path = 'E:/ML_Pharamachain/data/dataset/test/Fake/image123.jpg'\n",
    "predicted_class, confidence, probabilities = test_single_image(\n",
    "    image_path, model, val_test_transform, device, class_names\n",
    ")\n",
    "\n",
    "print(f\"Predicted: {predicted_class} ({confidence:.2f}% confidence)\")\n",
    "print(f\"Probabilities: Fake={probabilities[0]*100:.2f}%, Real={probabilities[1]*100:.2f}%\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n5️⃣  TESTING SUMMARY\")\n",
    "print(\"-\" * 60)\n",
    "test_summary = f\"\"\"\n",
    "Total test images: {len(test_labels)}\n",
    "Correct predictions: {np.sum(test_preds == test_labels)}\n",
    "Incorrect predictions: {np.sum(test_preds != test_labels)}\n",
    "\n",
    "Model is {'✅ GOOD' if accuracy >= 80 else '⚠️  NEEDS IMPROVEMENT' if accuracy >= 60 else '❌ POOR'}\n",
    "- If accuracy < 60%: Try more training, better data, or different model\n",
    "- If accuracy 60-80%: Good, but can be improved with more data/epochs\n",
    "- If accuracy > 80%: Excellent performance!\n",
    "\"\"\"\n",
    "print(test_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
